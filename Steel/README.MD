# Промышленность — Сталеплавильное производство

Построение модели, которая предскажет температуру для уменьшить потребление электроэнергии на этапе обработки стали.

# Описание этапа обработки

Сталь обрабатывают в металлическом ковше вместимостью около 100 тонн. Чтобы ковш выдерживал высокие температуры, изнутри его облицовывают огнеупорным кирпичом. Расплавленную сталь заливают в ковш и подогревают до нужной температуры графитовыми электродами. Они установлены в крышке ковша.

Из сплава выводится сера (десульфурация), добавлением примесей корректируется химический состав и отбираются пробы. Сталь легируют — изменяют её состав — подавая куски сплава из бункера для сыпучих материалов или проволоку через специальный трайб-аппарат (англ. tribe, «масса»).

Перед тем как первый раз ввести легирующие добавки, измеряют температуру стали и производят её химический анализ. Потом температуру на несколько минут повышают, добавляют легирующие материалы и продувают сплав инертным газом. Затем его перемешивают и снова проводят измерения. Такой цикл повторяется до достижения целевого химического состава и оптимальной температуры плавки.

Тогда расплавленная сталь отправляется на доводку металла или поступает в машину непрерывной разливки. Оттуда готовый продукт выходит в виде заготовок-слябов (англ. *slab*, «плита»).

# Описание данных

Данные состоят из файлов, полученных из разных источников:

-  data_arc.csv  — данные об электродах;
-  data_bulk.csv  — данные о подаче сыпучих материалов (объём);
-  data_bulk_time.csv  *—* данные о подаче сыпучих материалов (время);
-  data_gas.csv  — данные о продувке сплава газом;
-  data_temp.csv  — результаты измерения температуры;
-  data_wire.csv  — данные о проволочных материалах (объём);
-  data_wire_time.csv  — данные о проволочных материалах (время).

Во всех файлах столбец key содержит номер партии. В файлах может быть несколько строк с одинаковым значением key: они соответствуют разным итерациям обработки.
# Используемые библиотеки
- pandas
- numpy
- matplotlib
- seaborn
- sklearn
- lightgbm
- tensorflow.keras

## План выполнения работы

### Анализ тех процесса. Подготовка данных
- Подготовка данных
- Выбор и обработка данных влияющих на температуру
- Очистка данных от выбросов и аномалий.
- Объединение в одну таблицу.
### Подбор наиболее эффективной модели
- Проверке на мультиколлинеарность
- Разбивка на обучающую и тестовую выборки
- Выбор моделей по целевому показателю (регрессия)
- Линейная регрессия
- Дерево принятия решений для регрессии
- Случайный лес для регрессии
- Ансамбль LightGBM для регрессии
- Нейронная сеть
- Подбор параметров выбранных моделей для выбора максимально эффективной.
- Анализ важности факторов
- Тестирование максимально эффективных моделей

## Анализ тех процесса
Описание

**Результаты измерения температуры**

Все пропуски заменим нолями. Время между замерами посчитаем в секундах.
Сгруппируем записи по котлам (колонка key), в сгруппированную таблицу выведем начальную и конечную температуры.
Удалим все записи, где последнее измерение температуры равно 0, т.к. конечная температура это целевой признак, а создание синтетического целевого признака может ухудшить результат работы модели.
Удалим все записи, где начальная температура ниже 1500, так как это аномально холодные котлы которые встречаются очень редко

**Данные об электродах**

Подсчитаем затраченное на нагрев времени (в секундах) сумма всех нагреваний котла.

Сгруппируем записи по котлам (колонка key)
В сгруппированной таблице посчитаем среднюю активную и реактивную мощность, а так же количества нагреваний

**Данные о подаче сыпучих материалов и Данные о проволочных материалах**

Заполним все пропуски нолями, так как столбцы с пропусками это те добавки которые не попали в котел.

Найдём столбцы с низкими суммарными значениями (несколько котлов), удалим записи с добавлением таких присадок

Удалим сами столбцы, так такой признак будет бесполезен.

**Данные о продувке сплава газом**

Оставим без изменений так как таблица уже сгруппирована по котлам
